# Image segmenation

<p align="middle">
	<img src="/assets/example.png">
</p>

В данном ноутбуке содержится имплементация разных архитектур сверточных нейронных сетей для решения задачи сегментации изображений.
Имплементированы следующие модели:
<br>
**[Segnet](https://arxiv.org/pdf/1511.00561.pdf)**
<br>
**[Unet](https://arxiv.org/pdf/1505.04597.pdf)**
<br>

Для обучения сверточных нейронных сетей был использован датасет PH2. Датасет состоит из 200 снимков поражений кожи и их сегментированных изображений.
Обучение моделей выполнялось со следующими функциями потерь:
<br>
**BCE loss**
<br>
**Dice loss**
<br>
**Focal loss**
<br>

Для оценки качества моделей используется метрика **IoU**.

<img src="/assets/dataset_sample.png">

## Segnet
<p align="middle">
	<img src="/assets/segnet.png">
</p>

Архитектура сети состоит из энкодера, ботлнека и декодера. В энкодере используются несколько сверточных слоев с даунсемплингом:
<br>
**Conv2d > ReLU > BatchNorm2d > MaxPool2d**
<br>
На выходе энкодера получаем карты активации с вероятностями принадлежности пикселей к определенному классу. В нашем случае это вероятность того принадлежит ли пиксель поражению кожи или нет. Промежуточным слоем между энкодером и декодером является ботлнэк. Далее декодер восстанавливает сегментированное изображение из полученных карт активации. Декодер также состоит из сверточных слоев и апсемплинга:
<br>
**Conv2d > ReLU > BatchNorm2d > Upsample**
<br>
Также отличительной особенностью **Segnet** является передача индексов пулинга в соответствующие слои декодера для апсемплинга.

### Segnet результаты

<p align="middle">
	<img src="/assets/segnet_res.png">
</p>

## Unet

**U-Net** — это архитектура нейронной сети, которая получает изображение и выводит его. Первоначально он был задуман для семантической сегментации (как мы ее будем использовать), но он настолько успешен, что с тех пор используется в других контекстах. Получая на вход медицинское изображение, он выведет изображение в оттенках серого, где интенсивность каждого пикселя зависит от вероятности того, что этот пиксель принадлежит интересующей нас области.
<br>
У нас в архитектуре все так же существует энкодер и декодер, как в **SegNet**, но отличительной особеностью данной модели являются *skip-conenctions*, соединяющие части декодера и энкодера. То есть для того чтобы передать на вход декодера тензор, мы конкатенируем симметричный выход с энкодера и выход предыдущего слоя декодера.

<p align="middle">
	<img src="/assets/unet.png">
</p>

### Unet результаты
<p align="middle">
	<img src="/assets/unet_res.png">
</p>

### Unet-2
В данной имплементации **Unet** операции **Maxpooling** и **Upsample** заменены на сверточные слои **Convolutions** и **Transpose-convolutions**.


### Unet-2 результаты
<p align="middle">
	<img src="/assets/unet2_res.png">
</p>

## Заключение
<p align="middle">
	<img src="/assets/score_res.png">
</p>

Все модели показали приблизительно одинаковое качество по **IoU**, но лучше всех с задачей сегментации справилась модель Segnet с функцией потерь BCE.

<br>
Best model is segnet_bce_test_score with score: 0.8772720992565155
<br>
All models scores:
<br> 
segnet_bce_test_score: 0.8772720992565155
<br>
unet2_dice_test_score: 0.874285626411438
<br>
segnet_focal_test_score: 0.8671290278434753
<br>
unet_bce_test_score: 0.8660197854042053
<br>
unet2_bce_test_score: 0.8530789375305176
<br>
segnet_dice_test_score: 0.8511441051959991
<br>
unet_dice_test_score: 0.8265118598937988
<br>
unet2_focal_test_score: 0.7856417298316956
